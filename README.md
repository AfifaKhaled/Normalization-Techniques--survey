# Normalization-Techniques--Survey


 ##  Layer Normalization
 
 Layer Normalization  (Link for the paper ([https://arxiv.org/abs/2306.05745](https://arxiv.org/abs/1607.06450))
 
 ##  Batch Normalization
 Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift (Link for the paper (https://arxiv.org/abs/1502.03167)

## Instance Normalization
 Instance Normalization: The Missing Ingredient for Fast Stylization  (Link for the paper https://arxiv.org/abs/1607.08022)

## Local Response Normalization
 ImageNet Classification with Deep Convolutional Neural Networks (Link for the paper https://dl.acm.org/doi/10.1145/3065386)

## Adaptive Instance Normalization
 Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization (Link for the paper (https://arxiv.org/abs/1703.06868)) 
 
## Weight Demodulation
 Analyzing and Improving the Image Quality of StyleGAN (Link for the paper (https://arxiv.org/abs/1912.04958))

## Spectral Normalization
 Spectral Normalization for Generative Adversarial Networks  (Link for the paper (https://arxiv.org/abs/1802.05957))

 ## Conditional Batch Normalization
 Modulating early visual processing by language  (Link for the paper ((https://arxiv.org/abs/1707.00683))


 ## Weight Normalization
 Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks (Link for the paper ((https://arxiv.org/abs/1602.07868))

## Group Normalization
 Group Normalization  (Link for the paper (https://arxiv.org/abs/1803.08494))

 ## Activation Normalization
 Glow: Generative Flow with Invertible 1x1 Convolutions  (Link for the paper (https://arxiv.org/abs/1807.03039)


 ## Semantic Image Synthesis with Spatially-Adaptive Normalization

 
## Stable Rank Normalization for Improved Generalization in Neural Networks and GANs


## Is Second-order Information Helpful for Large-scale Visual Recognition?

## LayerScale
 Going deeper with Image Transformers (Link for the paper ([https://arxiv.org/abs/1502.03167](https://arxiv.org/pdf/2103.17239.pdf))

 ## Switchable Normalization
 Differentiable Learning-to-Normalize via Switchable Normalization (Link for the paper [([https://arxiv.org/abs/1502.03167](https://arxiv.org/pdf/2103.17239.pdf)](https://arxiv.org/abs/1806.10779))

 ## Weight Standardization
 Micro-Batch Training with Batch-Channel Normalization and Weight Standardization (Link for the paper ([[https://arxiv.org/abs/2306.05745](https://arxiv.org/abs/1607.06450)](https://arxiv.org/abs/1903.10520))
 

##  Local Contrast Normalization

 ## Gradient Normalization
 Gradient Normalization for Generative Adversarial Networks  (Link for the paper ([[[https://arxiv.org/abs/2306.05745](https://arxiv.org/abs/1607.06450)](https://arxiv.org/abs/1903.10520)](https://arxiv.org/abs/2109.02235))

 ## SyncBN
 Context Encoding for Semantic Segmentation (Link for the paper [([[[https://arxiv.org/abs/2306.05745](https://arxiv.org/abs/1607.06450)](https://arxiv.org/abs/1903.10520)](https://arxiv.org/abs/2109.02235))](https://arxiv.org/abs/1803.08904)

 ## Decorrelated Batch Normalization
 Decorrelated Batch Normalization  (Link for the paper [[([[[https://arxiv.org/abs/2306.05745](https://arxiv.org/abs/1607.06450)](https://arxiv.org/abs/1903.10520)](https://arxiv.org/abs/2109.02235))](https://arxiv.org/abs/1803.08904)](https://arxiv.org/abs/1804.08450)

 ## ReZero
 ReZero is All You Need: Fast Convergence at Large Depth(Link for the paper (https://arxiv.org/abs/2003.04887))
	
##  Attentive Normalization
 
 ## Conditional Instance Normalization
 
 ## Online Normalization
 Online Normalization for Training Neural Networks (Link for the paper ([https://arxiv.org/abs/2003.04887](https://arxiv.org/abs/1905.05894)))

 ## RMSNorm
 Root Mean Square Layer Normalization  (Link for the paper ([[https://arxiv.org/abs/2003.04887](https://arxiv.org/abs/1905.05894))](https://arxiv.org/abs/1910.07467))


 ## Cosine Normalization
 Cosine Normalization: Using Cosine Similarity Instead of Dot Product in Neural Networks  (Link for the paper ([[[https://arxiv.org/abs/2003.04887](https://arxiv.org/abs/1905.05894))](https://arxiv.org/abs/1910.07467))](https://arxiv.org/abs/1702.05870))


 ## Filter Response Normalization
 Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks (Link for the paper [([[[[https://arxiv.org/abs/2003.04887](https://arxiv.org/abs/1905.05894))](https://arxiv.org/abs/1910.07467))](https://arxiv.org/abs/1702.05870))
](https://arxiv.org/abs/1911.09737)](https://arxiv.org/abs/1911.09737)

 ## InPlace-ABN
 In-Place Activate)d BatchNorm for Memory-Optimized Training of DNNs (Link for the paper [[([[[[https://arxiv.org/abs/2003.04887](https://arxiv.org/abs/1905.05894))](https://arxiv.org/abs/1910.07467))](https://arxiv.org/abs/1702.05870))
](https://arxiv.org/abs/1911.09737)](https://arxiv.org/abs/1911.09737)
](https://ieeexplore.ieee.org/document/8578689/)

 ## BatchChannel Normalization
 Rethinking Normalization and Elimination Singularity in Neural Networks (Link for the paper https://arxiv.org/abs/1911.09738))

 ## Instance-Level Meta Normalization
 Instance-Level Meta Normalization  (Link for the paper  https://openaccess.thecvf.com/content_CVPR_2019/papers/Jia_Instance-Level_Meta_Normalization_CVPR_2019_paper.pdf)

##  Mixture Normalization
 Training Faster by Separating Modes of Variation in Batch-normalized Models Link for the paper ([[[[[https://arxiv.org/abs/2004.02967](https://arxiv.org/abs/2102.11382](https://arxiv.org/abs/1606.03498)](https://link.springer.com/article/10.1007/s11263-019-01269-y)](https://arxiv.org/abs/1810.05466)](https://pubmed.ncbi.nlm.nih.gov/30703010/))


## Mode Normalization
 Mode Normalization (Link for the paper ([[[[https://arxiv.org/abs/2004.02967](https://arxiv.org/abs/2102.11382](https://arxiv.org/abs/1606.03498)](https://link.springer.com/article/10.1007/s11263-019-01269-y)](https://arxiv.org/abs/1810.05466))

## Sparse Switchable Normalization
 SSN: Learning Sparse Switchable Normalization via SparsestMax (Link for the paper ([[[https://arxiv.org/abs/2004.02967](https://arxiv.org/abs/2102.11382](https://arxiv.org/abs/1606.03498)](https://link.springer.com/article/10.1007/s11263-019-01269-y))

## Virtual Batch Normalization
 Improved Techniques for Training GANs (Link for the paper ([[https://arxiv.org/abs/2004.02967](https://arxiv.org/abs/2102.11382](https://arxiv.org/abs/1606.03498))

 ## SaBN
 Sandwich Batch Normalization: A Drop-In Replacement for Feature Distribution Heterogeneity (Link for the paper ([https://arxiv.org/abs/2004.02967](https://arxiv.org/abs/2102.11382))

 ## EvoNorms
 Evolving Normalization-Activation Layers (Link for the paper (https://arxiv.org/abs/2004.02967))




